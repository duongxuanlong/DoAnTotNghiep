\chapter{Thực nghiệm và kết quả}
\label{Chapter4}
Chương này trình bày môi trường thực nghiệm của đồ án, các công cụ hỗ trợ thực nghiệm, các tập ngữ liệu được sử dụng, các công cụ dùng để đánh giá kết quả gom nhóm và kết quả của thực nghiệm.

\section{Thực nghiệm}
\subsection{Môi trường thực nghiệm}
%Môi trường thực nghiệm
Quá trình thực nghiệm đồ án được thực hiện với môi trường như sau:
\begin{enumerate}
\item[•]Ngôn ngữ lập trình Python phiên bản 2.7.
\item[•]Một số gói lệnh Python cài đặt thêm:
\begin{enumerate}
\item[-] gensim phiên bản 0.11.1: gói lệnh hỗ trợ trích xuất ngữ nghĩa của các chủ đề trong các văn bản.
Gensim được thiết kế để có thể thực thi với dữ liệu thô.
Các thuật toán trong gensim như Latent Semantics Analysis (LSA), Latent Dirichlet Allocation (LDA) và Random Projections dùng để khai thác cấu trúc ngữ nghĩa của văn bản bằng các mẫu thống kê.
Sau khi chạy các thuật toán này, văn bản thô sẽ chuyển sang dạng thể hiện mới có nghĩa và có thể truy vấn độ tương đồng với các văn bản khác.
Gensim là gói lệnh dùng để giải quyết các ý tưởng về ngữ liệu, vector và mô hình.
\item[-] scikit-learn phiên bản 0.16.1: gói lệnh hỗ trợ máy học trong Python.
Đây là công cụ đơn giản, hiệu quả cho khai thác và phân tích dữ liệu.
Các thuật toán trong scikit-learn là công cụ hỗ trợ rất tốt cho các đề tài nghiên cứu.
Scikit-learn là mã nguồn mở, có thể được sử dụng trong thương mại.
Vì vậy, scikit-learn là bộ thư viện hữu ích được sử dụng nhiều và có thể được tùy biến theo mục đích sử dụng.
\item[-] sgmlib là gói thư viện được hỗ trợ và tích hợp sẵn trong Python 2.7 và được sử dụng để trích xuất dữ liệu dưới định dạng SGML.
\end{enumerate}
\item[•]Ngôn ngữ lập trình C++.
%\item[•]Công cụ Google news để chọn lọc những bài báo đã được gom nhóm. 
\item[•]Công cụ Java tokenizer của tác giả Lê Hồng Phương - Đại Học Khoa Học Tự Nhiên - Đại Học Quốc gia Hà Nội - dùng để tách câu và tách từ cho tiếng Việt.
\item[•]Máy tính chạy thực nghiệm:
\begin{enumerate}
\item[-]CPU core i5 3.3GHz.
\item[-]RAM 8GB.
\item[-]Hệ điều hành Windows.
\end{enumerate}
\end{enumerate}

%\subsection{Công cụ hỗ trợ}
%\begin{table}[ht]
%\begin{center}
%\begin{tabularx}{\textwidth}{|c|c|X|}
%\hline
%STT & Tên công cụ & \makecell[c]{Mô tả} \\
%\hline
%1 & Google News & Công dụng: dùng để lọc ra những bài báo đã được gom nhóm. \\
%\hline
%2 & Java Tokenizer & Tác giả: Lê Hồng Phương - Đại học Khoa Học Tự nhiên - Đại học Quốc Gia Hà Nội. \newline Công dụng: Tách câu và tách từ cho tiếng Việt.\\
%\hline
%3 & sgmllib & Hỗ trợ: thư viện của Python 2.7. \newline Công dụng: dùng để trích xuất dữ liệu dưới định dạng SGML.\\
%\hline
%4 & C++ editor & Microsoft Visual Studio C++ 2008. \\
%\hline
%\end{tabularx}
%\caption[Các công cụ hỗ trợ thực nghiệm]{Các công cụ hỗ trợ thực nghiệm}
%\label{bang_4_1}
%\end{center}
%\end{table}

%\floatbarrier

\section{Dữ liệu}
%Giới thiệu dữ liệu sử dụng
Dữ liệu sử dụng trong chương trình bao gồm dữ liệu tiếng Anh và dữ liệu tiếng Việt.
Trong đó, bộ dữ liệu tiếng Việt được tổng hợp từ các trang tin tức nổi tiếng của Việt Nam như Vnexpress, Dân Trí, Tuổi Trẻ,\ldots 
Các bài báo của các bộ dữ liệu tiếng Việt được thu nhặt được thông qua trang tin tức tổng hợp của Google news.
Còn bộ dữ liệu tiếng Anh là các bài báo được lấy từ trang tin tức Reuters sau đó được tổng hợp lại thành bộ dữ liệu Reuters-21578~\cite{Reuters-21578}.
Cả hai bộ dữ liệu đều bao gồm các bài báo đã được gom nhóm sẵn.

%giới thiệu dữ liệu tiếng Anh
\subsection{Dữ liệu tiếng Anh}
% Giới thiệu Reuters-21578
Reuters-21578 bao gồm 21,578 bài báo từ trang tin tức Reuters.com\footnote{http://www.reuters.com/} bao gồm nhiều lĩnh vực khác nhau.
Bộ dữ liệu này được tổng hợp bởi David D. Lewis vào năm 1987.
Đây là nguồn tài nguyên cho mục đích nghiên cứu trong lĩnh vực truy vấn thông tin, máy học và những nghiên cứu dựa vào ngữ liệu khác.
Bộ dữ liệu này xuất bản và phân phối miễn phí cho mục đích nghiên cứu.
Nếu ai muốn sử dụng bộ dữ liệu này thì phải đề cập đến nguồn\footnote{http://www.research.att.com/\textasciitilde{}lewis} cũng như là trích dẫn thông tin của bộ dữ liệu trong đề tài nghiên cứu.

% Mô tả Reuters-21578
Reuters-21578 là tập dữ liệu bao gồm 22 tập tin dữ liệu.
Mỗi tập tin dữ liệu là có định dạng là Standard Generalized Markup Language (SGML) và có khoảng 1,000 bài báo.
Tuy nhiên, tập tin thứ 12 thì chỉ có 578 bài báo.
Ngoài ra, bộ dữ liệu còn có sáu tập tin mô tả phân loại dùng để chỉ mục cho dữ liệu.
Tập dữ liệu còn được bổ sung thêm dựa vào đóng góp của những nhà nghiên cứu khác.
Tất cả các tập tin đều được để dưới dạng thô không nén và được đóng gói lại thành reuters21578.tar.gz.

%Giới thiệu sơ bộ về SGML
SGML\footnote{https://www.w3.org/TR/WD-html40-970708/intro/sgmltut.html} là chuẩn cho việc định nghĩa ngôn ngữ đánh dấu cho văn bản, HTML là một trong những ứng dụng thành công của SGML.
SGML bao gồm phần khai báo, định nghĩa loại văn bản, đặc tả và thể hiện văn bản đánh dấu.
Phần khai báo SGML là chỉ ra các kí tự và các loại dấu phân cách sẽ sử dụng.
Phần định nghĩa loại văn bản định nghĩa cú pháp của cấu trúc đánh dấu và có thể có thêm các phần định nghĩa khác như là số và tên kí tự.
Phần đặc tả mô tả ngữ nghĩa được tạo bởi đánh dấu và phần đặc tả này ràng buộc sự giới hạn của cú pháp để không thể xuất hiện trong phần định nghĩa loại văn bản.
Thể hiện văn bản chứa nội dung và đánh dấu, mỗi thể hiện chứa tham chiếu đến phần định nghĩa văn bản để thực thi nó.

%  phần phân mục của Reuters-21578
Như đã đề cập, các bài báo trong Reuters-21578 đã được gom nhóm lại thành các tập phân nhóm khác nhau:
\begin{table}[ht]
\begin{center}
\begin{tabularx}{\textwidth}{|Y|Y|Y|Y|}
\hline
Tập phân nhóm & Số lượng phân nhóm con & Số lượng phân nhóm mà tần số lớn hơn một & Số lượng phân nhóm mà tần số lớn hơn 20  \\
\hline
EXCHANGES & 39 & 32 & 7\\
\hline
ORGS & 56 & 32 & 9\\
\hline
PEOPLE & 267 & 114 & 15 \\
\hline
PLACES & 175 & 147 & 60\\
\hline
TOPICS & 135 & 120 & 57\\
\hline
\end{tabularx}
\caption[Các tập phân nhóm]{Các tập phân nhóm}
\label{bang_4_2}
\end{center}
\end{table}

%Các tập phân loại
Phần phân nhóm TOPICS bao gồm các chủ đề về kinh tế.
Đây là phần sẽ bao gồm các bài báo mà có các từ sau thường xuyên xuất hiện như: ``include'', ``gold'', ``inventories'' và ``money-supply''.
Tập phân nhóm này là tập thường xuyên được sử dụng trong hầu hết các đề tài nghiên cứu về dữ liệu của Reuters.
Các tập phân nhóm như EXCHANGES, ORGS, PEOPLE, và PLACES gồm các bài báo được xếp vào nhóm có đúng như tên gọi, như ``nasdaq'' được xếp vào phân nhóm (EXCHANGES), ``gatt'' được xếp vào (ORGS), ``perez-de-cuellar'' được xếp vào (PEOPLE), và ``australia'' được xếp vào (PLACES).

%giới thiệu dữ liệu tiếng Việt
\subsection{Dữ liệu tiếng Việt}
%Giới thiệu sơ bộ
Bộ dữ liệu tiếng Việt được lấy từ trang tin tức tổng hợp Google news bao gồm 1,945 bài được phân chia thành 300 phân nhóm.
Các bài báo này đều đến từ các trang báo nổi tiếng của Việt Nam như: Vnexpress, Dân Trí, Tuổi Trẻ,\ldots
Bộ dữ liệu có 300 phân nhóm này được gán nhãn thủ công.
Trong đó, mỗi phân nhóm có ít nhất là 5 bài, nhiều nhất là 10 bài.
Do đây là bộ dữ liệu làm bằng thủ công nên để đảm bảo tính chính xác thì tôi đã phân nhóm lại một lần nữa để kiểm tra tính đúng đắn. 
Sau khi điều chỉnh những sai sót thì bộ dữ liệu này có thể được sử dụng như một bộ dữ liệu chuẩn cho gom nhóm văn bản.

%Giới thiệu công cụ để rút trích văn bản Google
Bộ dữ liệu này khởi đầu do Ung Văn Giàu xây dựng công cụ để rút trích các bài báo từ trang tin tức tổng hợp Google news.
Trong đó, công cụ để rút trích văn bản được viết bằng ngôn ngữ lập trình PHP.
Do việc truy vấn đến trang web Google news bị giới hạn nên số lượng bài báo lấy về không nhiều, chỉ khoảng 1,945.
Các bài báo sau khi được truy vấn về sẽ được lưu dưới dạng .txt hoặc .raw.
Trong quá trình lưu trữ, các bài báo cũng sẽ được gom nhóm thành các nhóm như trên trang Google news.

%Mô tả file txt
Bài báo khi được lưu xuống dưới định dạng .txt là bài báo gốc và sẽ được chia thành các trường để giúp cho việc thao thác sau này được dễ dàng.
Khi được lưu xuống dưới định dạng .txt, tập tin có các trường sau: ``Title'', ``Source'', ``Link'', ``Published Date'', ``Author'', ``Tags'', ``Summary'' và ``Content''.
Ý nghĩa của các trường là như sau:
\begin{enumerate}
\item[•]``Title'': tiêu đề bài báo.
\item[•]``Source'': tên trang báo (nếu có). Ví dụ: người đưa tin.
\item[•]``Link'': đường dẫn đến trang web.
\item[•]``Published Date'': ngày, giờ phát hành của bài báo.
\item[•]``Author'': tác giả bài báo.
\item[•]``Tags'': từ khóa của bài báo.
\item[•]``Summary'': tóm tắt của biên tập viên (nếu có).
\item[•]``Content'': nội dung bài báo (có thể gồm nhiều dòng).
\end{enumerate}

%Mô tả file raw
Trong khi đó, bài báo được lưu dưới định dạng .raw chứa các trường để phục vụ cho việc token và ner, các trường này được sắp xếp theo thứ tự như sau:
\begin{enumerate}
\item[•]``Title'': không xuất hiện chữ ``Title'' trong tập tin.
\item[•]``Tags'': không xuất hiện chữ ``Tags'' trong tập tin.
\item[•]``Summary'': chữ ``Summary'' sẽ chiếm 1 dòng trong tập tin.
\item[•]``Content'': chữ ``Content'' sẽ chiếm 1 dòng trong tập tin.
\end{enumerate}

%các định dạng khác
Sau khi có được tập dữ liệu thô được gom nhóm theo Google news, Giàu đã sử dụng công cụ Java Tokenzier của tác giả Lê Hồng Phương để tách câu và tách từ và tạo thành tập tin có định dạng là tok.
Tập tin có định dạng là tok có cấu trúc tương tự như tập tin có định dạng raw.
Để cho tiện sử dụng bộ dữ liệu, Giàu đã tích hợp phần dữ liệu sau khi tách câu và tách từ thành tập tin json có định dạng là .tok.json với các trường như sau: ``Title'', ``Tags'',  ``ShortIntro'' (tên gọi khác của ``Summary'') và ``Content''.
Ngoải ra, trong phần dữ liệu còn có tập tin có định dạng là .ner chứa kết quả sau khi NER (dùng công cụ C++ CLC NER của nhóm tác giả Đinh Điền) và có cấu trúc tương tự như tập tin có định dạng raw.
Tượng tự, Giàu cũng đã làm tập tin json có định dạng là .ner.json cho phần dữ liệu sau khi xử lý NER và có các trường tương tự như tập tin có định dạng là .tok.json.

%Quá trình xử lý từ văn bản thô sang dạng thể hiện để gom nhóm
Qui trình cuối cùng là Giàu đã đọc nội dung của từng bài báo, rồi sau đó đánh giá lại việc gom nhóm của Google có hợp lý hay không.
Nếu việc gom nhóm của Google là đúng thì bài báo sẽ vẫn được giữ nguyên trong phân nhóm hiện tại của Google.
Còn nếu bài báo bị xếp vào phân nhóm không hợp lý, Giàu sẽ tìm xem có thể xếp bài báo này vào các phân nhóm khác có sẵn hay không.
Trong trường hợp tìm được phân nhóm thích hợp thì bài báo sẽ được đưa vào phân nhóm này.
Ngược lại, bài báo sẽ được xếp vào một phân nhóm mới hoàn toàn.

%where
	%Thuc hien noi nao
	
%who
	%Do ai thuc nghiem 
%when
	%Duoc lay trong khoang thoi gian nao
	%
%why
	%Muc tieu cua viec lay du lieu dung de lam gi
%what
	%Mo ta cac bai bao sau khi thu hoach duoc
	%Sau khi co du lieu tho, dung de lam gi
%how
	%Su dung cong cu gi de ho tro
	%Trang web nao
	%Qua trinh kiem chung cac ket qua cua gom nhom Google
	%Co su dung tool gi de lay khong


%Các bước chuẩn bị cần thiết khi sử dụng dữ liệu

\section{Các phương pháp đánh giá}
%Các phương pháp đánh giá

%Giới thiệu các cách đánh giá
\subsection{Giới thiệu phương pháp đánh giá}
Để đánh giá kết quả gom nhóm văn bản, ta có hai loại chỉ số để sử dụng: chỉ số ngoại vi và chỉ số nội tại.
Chỉ số nội tại dùng để đo độ tốt của cấu trúc gom nhóm không cần thông tin ngoài.
Chỉ số ngoại vi dùng dùng để đo độ tương đồng giữa hai tập phân nhóm khác nhau.
Trong đó, tập phân nhóm thứ nhất là cấu trúc gom nhóm ban đầu đã được biết.
Còn tập phân nhóm thứ hai là kết quả từ quá trình gom nhóm.
Trong bài toán, ta sử dụng hai chỉ số đánh giá ngoại vi là : Normalized Mutual Information và Adjusted Rand Index.
	
Như đã đề cập ở phần trên, ta sẽ sử dụng hai chỉ số ngoại vi để đánh giá.
Sau đây, một vài thuật ngữ sẽ được giải thích trước khi ta bàn luận về hai chỉ số này.
Ta có tập $\textbf{C} \, = {C_1 \ldots C_i}$ là tập phân nhóm của đối tượng được xây dựng ở một cấp độ nhất định.
Tập $\textbf{P} \, = {P_1 \ldots P_j}$ là tập hợp được chia bởi phân nhóm ban đầu.
$I$ và $J$ là tương đương với số phân nhóm của $(|\textbf{C}|)$ và $(|\textbf{P}|)$.
Ta biểu diễn $n$ là tổng số đối tượng trong thuật toán.

%Cách đánh giá NMI
\subsection{Cách đánh giá NMI}

%Giới thiệu
%\subsubsection{Giới thiệu}
Normalized Mutual Information (NMI) có nguồn gốc từ Mutual Information (MI), trong đó MI sử dụng hướng tiếp cận là so sánh phân nhóm có nguồn gốc trong lý thuyết thông tin và dựa vào ý tưởng của entropy.
Gọi $S$ là entropy cho thông tin của văn bản $T$, ta có công thức sau:
\begin{center}
\begin{equation}
S(T) \, = -\sum_{i \in \sum} \frac{x_i}{n} \log_2 \frac{x_i}{n}
\end{equation}
\end{center}

Với $x_i$ là số lượng $i$ cần tìm kiếm trong $T$.
Giá trị entropy được được tính bằng số bit và $S(T)$, trong đó thì $\mid T \mid$ là số lượng bit cần để biểu diễn cho $T$.

Khi áp dụng gom nhóm, ý nghĩa của entropy được mô tả như sau: giả sử tất cả những thành phần của $X$ có xác xuất được chọn là giống nhau và chọn một thành phần ngẫu nhiên của $X$, xác xuất của thành phần này nằm trong phân nhóm $C_i \in C$ là $\frac{\mid C_i \mid}{n}$.
Khi đó, entropy kết hợp với phân nhóm $C$ cho ra công thức:
\begin{center}
\begin{equation}
H (C) = - \sum^{I}_{i = 1} \frac{x_i}{n} \log_2 \frac{x_i}{n}
\end{equation}
\end{center}

Độ entropy của một phân nhóm $C$ là thước đo cho sự bất định của phân nhóm đó trong thành phần được chọn ngẫu nhiên.
Trong trường hợp phân nhóm được xem là đơn giản khi chỉ có một phân nhóm hoặc có $n$ phân nhóm.
Ta có thể biết được phân nhóm của thành phần được chọn ngẫu nhiên.
Vì vậy, độ entropy khi đó được xem bằng $0$.

Ý tưởng về entropy có thể được mở rộng trong MI theo cách làm giảm độ bất định.
Ta có thể mô tả độ trung bình có thể để làm giảm độ bất định về phân nhóm của thành phần ngẫu nhiên được chọn.
Điều này có thể xảy ra khi ta biết được phân nhóm trong gom nhóm khác với tập các thành phần giống nhau.
Công thức để biểu diễn cho ý tưởng này:
\begin{center}
\begin{equation}
I (C, P) = \sum_{i=1}^I \sum_{j=1}^J \frac{x_{ij}}{n} log_2 \frac{n x_{ij}}{x_i x_j}
\end{equation}
\end{center}

Với $x_{ij}$ là số lượng thành phần mà nằm trong phân nhóm $C_i$ trong C lẫn phân nhóm $P_j$ trong $P$.
Độ thông tin hỗn hợp của $I$ là thước đo trong không gian của tất cả gom nhóm.
Tuy nhiên, giá trị này không bị chặn bởi một giá trị hằng nhất định nên gây khó khăn trong việc thực thi. Trong khi đó, độ hỗn hợp thông tin giữa hai gom nhóm bị chặn bởi 
\begin{center}
\begin{equation}
I (C, P) \leq min{H(C), H(P)}
\end{equation}
\end{center}

Đây là lý do cần thiết đẻ chuẩn hóa MI, vì vậy ta có NMI.
NMI được sử dụng nhiều trong lý thuyết xác suất và lý thuyết thông tin.
NMI được nâng cấp từ MI để đo phụ thuộc lẫn nhau giữa hai nhóm.
Từ đó, NMI cung cấp thông tin cân bằng liên quan đến số lượng phân nhóm.
Ngoài ra, NMI còn cho ra kết quả chia sẻ thông tin với lớp thực sự được gán và thông tin hỗn hợp trung bình giữa những cặp của phân nhóm mong đợi và phân nhóm kết quả.
		
%Công thức
%\subsubsection{Công thức}
\begin{center}
\begin{equation}
\textbf{NMI} = \frac{I(C,P)}{\sqrt{H(C)H(P)}}
\end{equation}
\begin{equation} \label{eq:NMI}
\longleftrightarrow \textbf{NMI} \, = \frac{\sum^I_{i=1} \sum^J_{j=1} x_{ij} \log \frac{n x_{ij}}{x_i x_j}}{\sqrt{\sum^I_{i=1} x_i \log \frac{x_i}{n} \sum^J_{j=1} x_j \log \frac{x_j}{n}}}
\end{equation}
\end{center}

Giá trị của chỉ số bị ràng buộc trong khoảng từ 0 đến 1.

Sau đây tôi sẽ trình bày ví dụ về cách tính cho chỉ số NMI.
Cho tập $S$ có các phần tử như sau: $S = {s_1, s_2, s_3, s_4, s_5, s_6, s_7, s_8, s_9}$.
Gọi tập $P$ là tập có kết quả gom nhóm thực tế của tập $S$:
\begin{enumerate}
\item[•] $P_1 = {s_1, \, s_2, \, s_3}$
\item[•] $P_2 = {s_4, \, s_5, \, s_6}$
\item[•] $P_3 = {s_7, \, s_8, \, s_9}$
\end{enumerate}
Khi ta thực thi chương trình gom nhóm trên tập $S$, ta có kết quả là tập $C$ như sau:
\begin{enumerate}
\item[•] $C_1 = {s_1, \, s_2, \, s_4}$
\item[•] $C_2 = {s_7, \, s_5, \, s_6}$
\item[•] $C_3 = {s_3, \, s_8, \, s_9}$
\end{enumerate}
%\begin{table}[ht]
%\begin{center}
%\begin{tabularx}{\textwidth}{|Y|Y|Y|}
%\hline
%$P_1$ & $P_2$ & $P_3$ \\
%\hline
%1 & 2 & 3\\
%
%1 & 2 & 3\\
%
%1 & 2 & 3\\
%\hline
%\end{tabularx}
%\caption[Các tập phân nhóm ban đầu]{Các tập phân nhóm ban đầu}
%\label{bang_4_3}
%\end{center}
%\end{table}

%\begin{table}[ht]
%\begin{center}
%\begin{tabularx}{\textwidth}{|Y|Y|Y|}
%\hline
%$P_1$ & $P_2$ & $P_3$\\
%\hline
%1 & 2 & 3\\
%
%1 & 2 & 3\\
%
%2 & 3 & 1\\
%\hline
%\end{tabularx}
%\caption[Kết quả gom nhóm]{Kết quả gom nhóm}
%\label{bang_4_4}
%\end{center}
%\end{table}

Dựa vào công thức \ref{eq:NMI}, ta có thể tính NMI có kết quả là: $0.16502$

%Ví dụ
%\subsubsection{Ví dụ}
		
%Cách đánh giá ARI
\subsection{Cách đánh giá ARI}
%Giới thiệu
%\subsubsection{Giới thiệu}
Adjusted Rand Index (ARI) được cải tiến từ chỉ số Rand Index (RI).
Trong đó, RI là chỉ số được dùng để đo những vấn đề của phân nhóm tiêu chuẩn khi mà kết quả của phân nhóm trong quá trình gom nhóm được so sánh với kết quả phân nhóm thực tế.
Cách tính hiệu quả thường được sử dụng cho chỉ số này là sử dụng tỷ lệ của các thành phần được gom nhóm chính xác với tất cả những thành phần khác.
Đối với RI, sự so sánh giữa hai phân nhóm là phần mở rộng so với việc đếm từng phần tử trong phân nhóm.
RI đã đếm số lượng phân nhóm của từng cặp với nhau.
\begin{center}
\begin{equation}
R(C,P) \, = \frac{n_{11} + n_{00}}{n(n - 1) / 2}
\end{equation}
\end{center}

Với $n_{11}$ và $n_{00}$ biểu thị tương ứng với số lượng các cặp đối tượng của cùng phân nhóm trong $\textbf{C}$ và trong $\textbf{P}$.
$R$ có giá trị từ 0 (không có cặp nào được phân nhóm giống nhau trong các phân nhóm) và 1 (giống nhau hoàn toàn).
Giá trị của $R$ phụ thuộc vào số lượng của phân nhóm cũng như là số lượng của các phần tử.
Morey và Agresi chỉ ra rằng RI phụ thuộc nhiều vào số lượng phân nhóm~\cite{Morey-Agresti}.

Giá trị lý tưởng của RI là miền ngẫu nghiên mà không có chứa giá trị hằng (như $0$).
Chính vì vậy, Hubert và Abarbie đề xuất sự điều chỉnh với việc đặt ra giả thiết phân phối siêu hình học tổng quát với siêu lý thuyết rỗng (null hyperthesis).
Hai tập được vẽ ngẫu nhiên với một số nhóm cố định và một số thành phần cố định trong mỗi nhóm (số lượng các nhóm cho mỗi tập có thể không giống nhau).
Sau đó, ta sẽ điều chỉnh cho RI về độ dị biệt và giá trị kì vọng dưới siêu lý thuyết rỗng.
\begin{center}
\begin{equation} \label{eq:ARI}
R_{adj}(\textbf{C}, \textbf{P}) = \frac{\sum^k_{i=1} \sum^l_{j=1} \binom {m_{ij}}  {2} - t_3}{\frac{1}{2} (t_1 + t_2) - t_3}
\end{equation}

\begin{equation} \label{eq:ARIParts}
t_1 = \sum^k_{i=1} \binom {|C_i|} {2} , t_2 = \sum_{j=1}^l \binom {|P_j|} {2}, t_3 = \frac{2 t_1 t_2}{n (n - 1)}
\end{equation}
\end{center}

Chỉ số này có giá trị kì vọng là 0 cho 2 tập phân nhóm độc lập hoàn toàn và có giá trị là 1 cho 2 tập phân nhóm giống nhau hoàn toàn.
Ý nghĩa của việc điều chỉnh cho cách tính này là đưa ra được câu hỏi cho giả thiết làm cách nào để phân phối.
Melina chỉ ra rằng một vài trường hợp có thể cho ra giá trị âm\cite{Melina-ARI}.

Sau đây là ví dụ về cách tính chỉ số ARI, cho bảng tần số về số lượng phần tử giao nhau của hai tập phân nhóm cần so sánh như sau:
\begin{table}[ht]
\begin{center}
\begin{tabular}{l|c c c|l}
\hline
$P \setminus C$ & $v_1$ & $v_2$ & $v_3$ & $Sums$ \\
\hline
$u_1$ & 1 & 1 & 0 & 2 \\
$u_2$ & 1 & 2 & 1 & 4 \\
$u_3$ & 0 & 0 & 4 & 4 \\
\hline
$Sums$ & 2 & 3 & 5 & $n = 10$ \\
\end{tabular}
\caption[Bảng tần số]{Bảng tần số về số lượng phần tử giao nhau của hai phân nhóm}
\label{bang_4_5}
\end{center}
\end{table}

Dựa vào công thức \ref{eq:ARI}, ta sẽ có được kết quả là $0.313$.

% được sử dụng thống kê và gom nhóm dữ liệu.
%RI dùng để đo độ tương đồng giữa các nhóm dữ liệu.
%Vấn đề của RI là giá trị mong muốn của hai phân nhóm ngẫu nhiên nằm trong khoảng từ $0$ và $1$.
%Vì vậy, ARI ra đời là phiên bản chỉnh sửa có thể định nghĩa cho việc điều chỉnh cho cơ hội gom nhóm các thành phần.
%Giá trị của ARI có thể nằm trong phạm vi từ -1 đến 1.
%
%%Công thức
%\subsubsection{Công thức}
%\begin{center}
%\begin{equation}
%E[\alpha] \, = \frac{\pi(C) \cdot \pi(P)}{n(n - 1) / 2}
%\end{equation}
%\end{center}
%		
%Với $\pi(C)$ và $\pi(P)$ biểu thị tương ứng với số lượng các cặp đối tượng của cùng phân nhóm trong $\textbf{C}$ và cùng phân lớp trong $\textbf{P}$. Giá trị lớn nhất cho $\alpha$ có thể đạt được là:
%\begin{center}
%\begin{equation}
%\max(\alpha) = \frac{1}{2} (\pi(C) + \pi(P))
%\end{equation}
%\end{center}
%		
%Độ tương đồng giữa $\textbf{C}$ và $\textbf{P}$ có thể được ước lượng bởi adjusted rand index như sau:
%
%\begin{center}
%\begin{equation}
%R(\textbf{C}, \textbf{P}) = \frac{\alpha - E[\alpha]}{\max(\alpha) - E[\alpha]}
%\end{equation}
%\end{center}
%
%
%%Ví dụ
%\subsubsection{Ví dụ}

\section{Kết quả}
%Thực nghiệm kết quả
Sau đây, kết quả của phần thực nghiệm của thuật toán Kmeans và HAC được thể hiện dưới các bảng sau:

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{7}{|c|}{Kmeans}                                                                                               \\ \hline
                                                         & \multicolumn{3}{c|}{ARI}       & \multicolumn{3}{c|}{NMI}       \\ \hline
                                                         & Kmeans++ & Random   & NDArray  & Kmeans++ & Random   & NDArray  \\ \hline
Doc2Vec                                                  & 0.619 & 0.571 & 0.629 & 0.805 & 0.717 & 0.813 \\ \hline
TF-IDF                                                   & 0.114 & 0.616 & 0.117 & 0.623 & 0.770 & 0.629 \\ \hline
\begin{tabular}[c]{@{}c@{}}TF-IDF\\ Doc2Vec\end{tabular} & 0.589 & 0.515 &       & 0.810 & 0.724 &          \\ \hline
\end{tabular}%
}
\caption[Kết quả thực nghiệm Kmeans trên dữ liệu tiếng Việt]{Kết quả thực nghiệm Kmeans trên dữ liệu tiếng Việt}
\label{bang_4_6}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{8}{|c|}{HAC - Agglomerative Clustering}                                                                                                      \\ \hline
                                                                          &             & \multicolumn{3}{c|}{ARI}       & \multicolumn{3}{c|}{NMI}       \\ \hline
                                                                          &             & Ward     & Complete & Average  & Ward     & Complete & Average  \\ \hline
\multirow{6}{*}{Doc2Vec}                                                  & euclidean   & 0.812 & 0.740 & 0.417 & 0.884 & 0.836 & 0.749 \\ \cline{2-8} 
                                                                          & I1          & x     & 0.726 & 0.423 & x     & 0.824 & 0.748 \\ \cline{2-8} 
                                                                          & I2          & x     & 0.740 & 0.417 & x     & 0.836 & 0.749 \\ \cline{2-8} 
                                                                          & manhattan   & x     & 0.726 & 0.423 & x     & 0.824 & 0.748 \\ \cline{2-8} 
                                                                          & cosine      & x     & 0.740 & 0.677 & x     & 0.832 & 0.805 \\ \cline{2-8} 
                                                                          & precomputed & x     &       &       & x     &          &          \\ \hline
\multirow{6}{*}{TF-IDF}                                                    & euclidean   & 0.821 & 0.827 & 0.722 & 0.910 & 0.897 & 0.877 \\ \cline{2-8} 
                                                                          & I1          & x     & 0.301 & 0.031 & x     & 0.700 & 0.406 \\ \cline{2-8} 
                                                                          & I2          & x     & 0.827 & 0.722 & x     & 0.897 & 0.877 \\ \cline{2-8} 
                                                                          & manhattan   & x     & 0.301 & 0.031 & x     & 0.701 & 0.406 \\ \cline{2-8} 
                                                                          & cosine      & x     & 0.787 & 0.799 & x     & 0.870 & 0.878 \\ \cline{2-8} 
                                                                          & precomputed & x     &       &       & x     &       &          \\ \hline
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ Doc2Vec\end{tabular}} & euclidean   & 0.837 & 0.770 & 0.493 & 0.903 & 0.863 & 0.789 \\ \cline{2-8} 
                                                                          & I1          & x     & 0.718 & 0.283 & x     & 0.844 & 0.737 \\ \cline{2-8} 
                                                                          & I2          & x     & 0.770 & 0.493 & x     & 0.863 & 0.789 \\ \cline{2-8} 
                                                                          & manhattan   & x     & 0.718 & 0.283 & x     & 0.844 & 0.737 \\ \cline{2-8} 
                                                                          & cosine      & x     & 0.772 & 0.722 & x     & 0.855 & 0.831 \\ \cline{2-8} 
                                                                          & precomputed & x     &       &       & x     &       &          \\ \hline
\end{tabular}%
}
\caption[Kết quả thực nghiệm HAC trên dữ liệu tiếng Việt]{Kết quả thực nghiệm HAC trên dữ liệu tiếng Việt}
\label{bang_4_7}
\end{table}

%Giải thích chi tiết(5 đoạn)
\section{Thảo luận}

%%18


