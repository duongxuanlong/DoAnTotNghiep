\chapter{Thực nghiệm và kết quả}
\label{Chapter4}
Chương này trình bày môi trường thực nghiệm của đồ án, các công cụ hỗ trợ thực nghiệm, các tập ngữ liệu được sử dụng, các công cụ dùng để đánh giá kết quả gom nhóm và kết quả của thực nghiệm.

\section{Thực nghiệm}
\subsection{Môi trường thực nghiệm}
%Môi trường thực nghiệm
Quá trình thực nghiệm đồ án được thực hiện với môi trường như sau:
\begin{enumerate}
\item[•]Ngôn ngữ lập trình Python phiên bản 2.7.
\item[•]Một số gói lệnh Python cài đặt thêm:
\begin{enumerate}
\item[-] gensim phiên bản 0.11.1: gói lệnh hỗ trợ trích xuất ngữ nghĩa của các chủ đề trong các văn bản.
Gensim được thiết kế để có thể thực thi với dữ liệu thô.
Các thuật toán trong gensim như Latent Semantics Analysis (LSA), Latent Dirichlet Allocation (LDA) và Random Projections dùng để khai thác cấu trúc ngữ nghĩa của văn bản bằng các mẫu thống kê.
Sau khi chạy các thuật toán này, văn bản thô sẽ chuyển sang dạng thể hiện mới có nghĩa và có thể truy vấn độ tương đồng với các văn bản khác.
Gensim là gói lệnh dùng để giải quyết các ý tưởng về ngữ liệu, vector và mô hình.
\item[-] scikit-learn phiên bản 0.16.1: gói lệnh hỗ trợ máy học trong Python.
Đây là công cụ đơn giản, hiệu quả cho khai thác và phân tích dữ liệu.
Các thuật toán trong scikit-learn là công cụ hỗ trợ rất tốt cho các đề tài nghiên cứu.
Scikit-learn là mã nguồn mở, có thể được sử dụng trong thương mại.
Vì vậy, scikit-learn là bộ thư viện hữu ích được sử dụng nhiều và có thể được tùy biến theo mục đích sử dụng.
\item[-] sgmlib là gói thư viện được hỗ trợ và tích hợp sẵn trong Python 2.7 và được sử dụng để trích xuất dữ liệu dưới định dạng SGML.
\end{enumerate}
\item[•]Ngôn ngữ lập trình C++.
\item[•]Công cụ Google news để chọn lọc những bài báo đã được gom nhóm.
\item[•]Công cụ Java tokenizer của tác giả Lê Hồng Phương - Đại Học Khoa Học Tự Nhiên - Đại Học Quốc gia Hà Nội - dùng để tách câu và tách từ cho tiếng Việt.
\item[•]Máy tính chạy thực nghiệm:
\begin{enumerate}
\item[-]CPU core i5 3.3GHz.
\item[-]RAM 8GB.
\item[-]Hệ điều hành windows.
\end{enumerate}
\end{enumerate}

%\subsection{Công cụ hỗ trợ}
%\begin{table}[ht]
%\begin{center}
%\begin{tabularx}{\textwidth}{|c|c|X|}
%\hline
%STT & Tên công cụ & \makecell[c]{Mô tả} \\
%\hline
%1 & Google News & Công dụng: dùng để lọc ra những bài báo đã được gom nhóm. \\
%\hline
%2 & Java Tokenizer & Tác giả: Lê Hồng Phương - Đại học Khoa Học Tự nhiên - Đại học Quốc Gia Hà Nội. \newline Công dụng: Tách câu và tách từ cho tiếng Việt.\\
%\hline
%3 & sgmllib & Hỗ trợ: thư viện của Python 2.7. \newline Công dụng: dùng để trích xuất dữ liệu dưới định dạng SGML.\\
%\hline
%4 & C++ editor & Microsoft Visual Studio C++ 2008. \\
%\hline
%\end{tabularx}
%\caption[Các công cụ hỗ trợ thực nghiệm]{Các công cụ hỗ trợ thực nghiệm}
%\label{bang_4_1}
%\end{center}
%\end{table}

%\floatbarrier

\section{Dữ liệu}
%Giới thiệu dữ liệu sử dụng
Dữ liệu sử dụng trong chương trình bao gồm dữ liệu tiếng Anh và dữ liệu tiếng Việt.
Trong đó, bộ dữ liệu tiếng Việt được tổng hợp từ các trang tin tức nổi tiếng của Việt Nam như Vnexpress, Dân Trí, Tuổi Trẻ,\ldots 
Các bài báo của các bộ dữ liệu tiếng Việt được thu nhặt được thông qua trang tin tức tổng hợp của Google news.
Còn bộ dữ liệu tiếng Anh là các bài báo được lấy từ trang tin tức Reuters được tổng hợp lại thành Reuters-21578.
Cả hai bộ dữ liệu đều bao gồm các bài báo đã được gom nhóm.

%giới thiệu dữ liệu tiếng Anh
\subsection{Dữ liệu tiếng Anh}
% Giới thiệu Reuters-21578
Reuters-21578 bao gồm 21,578 bài báo thuộc nhiều lĩnh vực khác nhau.
Bộ dữ liệu này được tổng hợp bởi David D. Lewis vào năm 1987.
Đây là nguồn tài nguyên cho mục đích nghiên cứu trong lĩnh vực truy vấn thông tin, máy học, và những nghiên cứu dựa vào ngữ liệu khác.
Bộ dữ liệu này xuất bản và phân phối miễn phí cho mục đích nghiên cứu.
Nếu người nào muốn sử dụng bộ dữ liệu này thì phải đề cập đến nguồn~\footnote{http://www.research.att.com/~lewis} cũng như là thông tin tên của bộ dữ liệu cho mọi người biết.

% Mô tả Reuters-21578
Reuters-21578 là tập dữ liệu bao gồm hai mươi hai tập tin dữ liệu.
Mỗi tập tin dữ liệu là có định dạng là Standard Generalized Markup Language (SGML) và có khoảng 1,000 bài báo.
Ngoài ra, bộ dữ liệu còn có sáu tập tin mô tả phân loại dùng để chỉ mục cho dữ liệu.
Tập dữ liệu còn có thêm vào những tập tin dựa vào đóng góp của những nhà nghiên cứu khác.
Tất cả những tập tin đều là không có nén, được gom lại vào thành một thư mục được nén lại thành cái tên reuters21578.tar.gz

%Giới thiệu sơ bộ về SGML
SGML~\footnote{https://www.w3.org/TR/WD-html40-970708/intro/sgmltut.html} là chuẩn cho việc định nghĩa ngôn ngữ đánh dấu cho văn bản, HTML là một trong những ứng dụng của SGML.
SGML bao gồm phần khai báo, định nghĩa loại văn bản, đặc tả và thể hiện văn bản đánh dấu.
Phần khai báo SGML là chỉ ra các kí tự và các loại dấu phân cách sẽ sử dụng.
Phần định nghĩa loại văn bản định nghĩa cú pháp của cấu trúc đánh dấu và có thể có thêm các phần định nghĩa khác như là số và tên kí tự.
Phần đặc tả mô tả ngữ nghĩa được tạo bởi đánh dấu và phần đặc tả này ràng buộc sự giới hạn của cú pháp để không thể xuất hiện trong phần định nghĩa loại văn bản.
Thể hiện văn bản chứa nội dung và đánh dấu, mỗi thể hiện chứa tham chiếu đến phần định nghĩa văn bản để thực thi nó.

%  phần phân mục của Reuters-21578
Như đã đề cập, các bài báo trong reuters-21578 đã được gom nhóm lại thành các tập phân nhóm khác nhau
\begin{table}[ht]0
\begin{center}
\begin{tabularx}{\textwidth}{|Y|Y|Y|Y|}
\hline
Tập phân loại & Số lượng phân phân nhóm & Số lượng phân nhóm mà tần số lớn hơn một & Số lượng phân nhóm mà tần số lớn hơn 20  \\
\hline
EXCHANGES & 39 & 32 & 7\\
\hline
ORGS & 56 & 32 & 9\\
\hline
PEOPLE & 267 & 114 & 15 \\
\hline
PLACES & 175 & 147 & 60\\
\hline
TOPICS & 135 & 120 & 57\\
\hline
\end{tabularx}
\caption[Các tập phân loại]{Các tập phân loại}
\label{bang_4_2}
\end{center}
\end{table}

%Các tập phân loại
Phần phân loại TOPICS bao gồm các chủ đề về kinh tế.
Ví dụ phần này sẽ bao gồm các từ chính như ``include'', ``gold'', ``inventories'', và ``money-supply''.
Tập phân loại này là tập đã được sử dụng hầu hết trong các nghiên cứu về dữ liệu của Reuters.
Các tập phân loại như EXCHANGES, ORGS, PEOPLE, và PLACES được xếp nhóm có tên như mô tả, ví dụ như ``nasdaq'' (EXCHANGES), ``gatt'' (ORGS), ``perez-de-cuellar'' (PEOPLE), và ``australia'' (PLACES).

%giới thiệu dữ liệu tiếng Việt
\subsection{Dữ liệu tiếng Việt}
Bộ dữ liệu tiếng Việt do Ung Văn Giàu lấy thủ công từ Google News bao gồm 1945 bài có tổng cộng là 300 phân nhóm.
Các bài báo này đều đến từ các trang báo như: Vnexpress,Dân Trí, Tuổi Trẻ,\ldots
Bộ dữ liệu có 300 phân nhóm là do bạn Giàu gán nhãn những bài vào các phân nhóm.
Mỗi phân nhóm có ít nhất là 5 bài, nhiều nhất là 10 bài.
Do đây là bộ dữ liệu làm bằng thủ công nên để đảm bảo tính chính xác thì em phân nhóm lại một lần nữa. 
Việc có hai bạn độc lập kiểm tra bộ dữ liệu nên đây là bộ dữ liệu đã được qua kiểm chứng và có thể sử dụng cho mục đích nghiên cứu.


%Các bước chuẩn bị cần thiết khi sử dụng dữ liệu

\section{Các phương pháp đánh giá}
%Các phương pháp đánh giá

%Giới thiệu các cách đánh giá
\subsection{Giới thiệu phương pháp đánh giá}
Để đánh giá kết quả gom nhóm văn bản, ta có hai loại chỉ số để sử dụng: chỉ số ngoại vi và chỉ số nội tại.
Chỉ số nội tại dùng để đo độ tốt của cấu trúc gom nhóm không cần thông tin ngoài.
Chỉ số ngoại vi dùng dùng để đo độ tương đồng giữa hai phân nhóm.
Trong đó, phân nhóm thứ nhất là cấu trúc gom nhóm gốc đã được biết.
Còn phân nhóm thứ hai là kết quả từ quá trình gom nhóm.
Trong bài toán, ta sử dụng hai chỉ số đánh giá ngoại vi là : Normalized Mutual Information (NMI) và Adjusted Rand Index (ARI).
	
Như đã đề cập ở phần trên, ta sẽ sử dụng hai chỉ số ngoại vi để đánh giá.
Sau đây, một vài thuật ngữ sẽ được giải thích trước khi ta bàn luận về hai chỉ số này.
Ta có tập $\textbf{C} \, = {C_1 \ldots C_i}$ là tập phân nhóm của đối tượng được xây dựng ở một cấp độ nhất định.
Tập $\textbf{P} \, = {P_1 \ldots P_j}$ là tập hợp được chia bởi phân lớp ban đầu.
$I$ và $J$ là tương đương với số phân nhóm của $(|\textbf{C}|)$ và số phân lớp của  $(|\textbf{P}|)$.
Ta biểu diễn $n$ là tổng số đối tượng trong thuật toán.

%Cách đánh giá NMI
\subsection{Cách đánh giá NMI}

%Giới thiệu
%\subsubsection{Giới thiệu}
NMI có nguồn gốc từ Mutual Information (MI), trong đó MI sử dụng hướng tiếp cận là so sánh phân nhóm có nguồn gốc trong lý thuyết thông tin và dựa vào ý tưởng của entropy.
Gọi $S$ là entropy cho thông tin của văn bản $T$, ta có công thức sau:
\begin{center}
\begin{equation}
S(T) \, = -\sum_{i \in \sum} \frac{x_i}{n} \log_2 \frac{x_i}{n}
\end{equation}
\end{center}

Với $x_i$ là số lượng $i$ cần tìm kiếm trong $T$.
Giá trị entropy được được tính bằng số bit và $S(T)$, trong đó thì $\mid T \mid$ là số lượng bit cần để biểu diễn cho $T$.

Khi áp dụng gom nhóm, ý nghĩa của entropy được mô tả như sau: giả sử tất cả những thành phần của $X$ có xác xuất được chọn là giống nhau và chọn một thành phần ngẫu nhiên của $X$, xác xuất của thành phần này nằm trong phân nhóm $C_i \in C$ là $\frac{\mid C_i \mid}{n}$.
Khi đó, entropy kết hợp với phân nhóm $C$ cho ra công thức:
\begin{center}
\begin{equation}
H (C) = - \sum^{I}_{i = 1} \frac{x_i}{n} \log_2 \frac{x_i}{n}
\end{equation}
\end{center}

Độ entropy của một phân nhóm $C$ là thước đo cho sự bất định của phân nhóm đó trong thành phần được chọn ngẫu nhiên.
Trong trường hợp phân nhóm được xem là đơn giản khi chỉ có một phân nhóm hoặc có $n$ phân nhóm.
Ta có thể biết được phân nhóm của thành phần được chọn ngẫu nhiên.
Vì vậy, độ entropy khi đó được xem bằng $0$.

Ý tưởng về entropy có thể được mở rộng trong MI theo cách làm giảm độ bất định.
Ta có thể mô tả trung bình có thể làm giảm độ bất định về phân nhóm của thành phần ngẫu nhiên được chọn.
Điều này có thể xảy ra khi ta biết được phân nhóm trong gom nhóm khác với tập các thành phần giống nhau.
Công thức để biểu diễn cho ý tưởng này:
\begin{center}
\begin{equation}
I (C, P) = \sum_{i=1}^I \sum_{j=1}^J \frac{x_{ij}}{n} log_2 \frac{n x_{ij}}{x_i x_j}
\end{equation}
\end{center}

Với $x_{ij}$ là số lượng thành phần mà nằm trong phân nhóm $C_i$ trong C lẫn phân nhóm $P_j$ trong $P$.
Độ thông tin hỗn hợp của $I$ là thước đo trong không gian của tất cả gom nhóm.
Tuy nhiên, giá trị này không bị chặn bởi một giá trị hằng nhất định nên gây khó khăn trong việc thực thi. Trong khi đó, độ hỗn hợp thông tin giữa hai gom nhóm bị chặn bởi 
\begin{center}
\begin{equation}
I (C, P) \leq min{H(C), H(P)}
\end{equation}
\end{center}

Đây là lý do cần thiết đẻ chuẩn hóa MI, vì vậy ta có NMI.
NMI được sử dụng nhiều trong lý thuyết xác suất và lý thuyết thông tin.
NMI được nâng cấp từ MI để đo phụ thuộc lẫn nhau giữa hai nhóm.
Từ đó, NMI cung cấp thông tin cân bằng liên quan đến số lượng phân nhóm.
Ngoài ra, NMI còn cho ra kết quả chia sẻ thông tin với lớp thực sự được gán và thông tin hỗn hợp trung bình giữa những cặp của phân nhóm và phân lớp.
		
%Công thức
%\subsubsection{Công thức}
\begin{center}
\begin{equation}
\textbf{NMI} = \frac{I(C,P)}{\sqrt{H(C)H(P)}}
\end{equation}
\begin{equation} \label{eq:NMI}
\longleftrightarrow \textbf{NMI} \, = \frac{\sum^I_{i=1} \sum^J_{j=1} x_{ij} \log \frac{n x_{ij}}{x_i x_j}}{\sqrt{\sum^I_{i=1} x_i \log \frac{x_i}{n} \sum^J_{j=1} x_j \log \frac{x_j}{n}}}
\end{equation}
\end{center}

Giá trị của chỉ số bị ràng buộc trong khoảng từ 0 đến 1.

Sau đây là ví dụ về cách tính cho chỉ số NMI, cho 2 bảng sau:
\begin{table}[ht]
\begin{center}
\begin{tabularx}{\textwidth}{|Y|Y|Y|}
\hline
$P_1$ & $P_2$ & $P_3$ \\
\hline
1 & 2 & 3\\

1 & 2 & 3\\

1 & 2 & 3\\
\hline
\end{tabularx}
\caption[Các tập phân nhóm ban đầu]{Các tập phân nhóm ban đầu}
\label{bang_4_3}
\end{center}
\end{table}

\begin{table}[ht]
\begin{center}
\begin{tabularx}{\textwidth}{|Y|Y|Y|}
\hline
$P_1$ & $P_2$ & $P_3$\\
\hline
1 & 2 & 3\\

1 & 2 & 3\\

2 & 3 & 1\\
\hline
\end{tabularx}
\caption[Kết quả gom nhóm]{Kết quả gom nhóm}
\label{bang_4_4}
\end{center}
\end{table}

Dựa vào công thức \ref{eq:NMI}, ta có thể tính NMI có kết quả là: $0.16502$

%Ví dụ
%\subsubsection{Ví dụ}
		
%Cách đánh giá ARI
\subsection{Cách đánh giá ARI}
%Giới thiệu
%\subsubsection{Giới thiệu}
ARI được cải tiến từ chỉ số RI.
Trong đó, RI là chỉ số được dùng để đo những vấn đề của phân lớp tiêu chuẩn khi mà kết quả của quá trình phân lớp được so sánh với kết quả thực tế.
Cách tính hiệu quả thường được sử dụng cho vấn đề này là sử dụng tỷ lệ mà các thành phần được phân lớp chính xác với tất cả những thành phần khác.
Đối với RI, sự so sánh giữa hai phân nhóm là phần mở rộng so với việc đếm từng phần tử trong phân nhóm.
RI đã đếm số lượng phân nhóm của từng cặp với nhau.
\begin{center}
\begin{equation}
R(C,P) \, = \frac{n_{11} + n_{00}}{n(n - 1) / 2}
\end{equation}
\end{center}

Với $n_{11}$ và $n_{00}$ biểu thị tương ứng với số lượng các cặp đối tượng của cùng phân nhóm trong $\textbf{C}$ và cùng phân lớp trong $\textbf{P}$.
$R$ có giá trị từ 0(không có cặp nào được phân nhóm giống nhau trong các phân nhóm) và 1(giống nhau hoàn toàn).
Giá trị của $R$ phụ thuộc vào số lượng của phân nhóm cũng như là số lượng của các phần tử.
Morey và Agresi chỉ ra rằng RI phụ thuộc nhiều vào số lượng phân nhóm.

Giá trị lý tưởng của RI là miền ngẫu nghiên mà không có chứa giá trị hằng (như $0$).
Chính vì vậy, Hubert và Abarbie đề xuất sự điều chỉnh với việc đặt ra giả thiết phân phối siêu hình học tông quát với siêu lý thuyết rỗng (null hyperthesis).
Hai tập được vẽ ngẫu nhiên với một số nhóm cố định và một số thành phần cố định trong mỗi nhóm(số lượng các nhóm cho mỗi tập có thể không giống nhau).
Sau đó, ta sẽ điều chỉnh RI độ dị biệt và giá trị kì vọng dưới siêu lý thuyết rỗng.
\begin{center}
\begin{equation} \label{eq:ARI}
R_{adj}(\textbf{C}, \textbf{P}) = \frac{\sum^k_{i=1} \sum^l_{j=1} \binom {m_{ij}}  {2} - t_3}{\frac{1}{2} (t_1 + t_2) - t_3}
\end{equation}

\begin{equation} \label{eq:ARIParts}
t_1 = \sum^k_{i=1} \binom {|C_i|} {2} , t_2 = \sum_{j=1}^l \binom {|P_j|} {2}, t_3 = \frac{2 t_1 t_2}{n (n - 1)}
\end{equation}
\end{center}

Chỉ số này có giá trị kì vọng là 0 cho 2 tập độc lập và 1 cho 2 tập giống nhau hoàn toàn.
Ý nghĩa của việc điều chỉnh cho cách tính này là đưa ra được câu hỏi cho giả thiết làm cách nào để phân phối.
Melina chỉ ra rằng một vài trường hợp có thể cho ra giá trị âm.

Sau đây là ví dụ về cách tính chỉ số ARI, cho bảng tần số ngẫu nghiên sau:
\begin{table}[ht]
\begin{center}
\begin{tabular}{l|c c c|l}
\hline
$P \setminus C$ & $v_1$ & $v_2$ & $v_3$ & $Sums$ \\
\hline
$u_1$ & 1 & 1 & 0 & 2 \\
$u_2$ & 1 & 2 & 1 & 4 \\
$u_3$ & 0 & 0 & 4 & 4 \\
\hline
$Sums$ & 2 & 3 & 5 & $n = 10$ \\
\end{tabular}
\caption[Bảng tần số ngẫu nhiên]{Bảng tần số ngẫu nhiên}
\label{bang_4_5}
\end{center}
\end{table}

Dựa vào công thức \ref{eq:ARI}, ta sẽ có được kết quả là $0.313$

% được sử dụng thống kê và gom nhóm dữ liệu.
%RI dùng để đo độ tương đồng giữa các nhóm dữ liệu.
%Vấn đề của RI là giá trị mong muốn của hai phân nhóm ngẫu nhiên nằm trong khoảng từ $0$ và $1$.
%Vì vậy, ARI ra đời là phiên bản chỉnh sửa có thể định nghĩa cho việc điều chỉnh cho cơ hội gom nhóm các thành phần.
%Giá trị của ARI có thể nằm trong phạm vi từ -1 đến 1.
%
%%Công thức
%\subsubsection{Công thức}
%\begin{center}
%\begin{equation}
%E[\alpha] \, = \frac{\pi(C) \cdot \pi(P)}{n(n - 1) / 2}
%\end{equation}
%\end{center}
%		
%Với $\pi(C)$ và $\pi(P)$ biểu thị tương ứng với số lượng các cặp đối tượng của cùng phân nhóm trong $\textbf{C}$ và cùng phân lớp trong $\textbf{P}$. Giá trị lớn nhất cho $\alpha$ có thể đạt được là:
%\begin{center}
%\begin{equation}
%\max(\alpha) = \frac{1}{2} (\pi(C) + \pi(P))
%\end{equation}
%\end{center}
%		
%Độ tương đồng giữa $\textbf{C}$ và $\textbf{P}$ có thể được ước lượng bởi adjusted rand index như sau:
%
%\begin{center}
%\begin{equation}
%R(\textbf{C}, \textbf{P}) = \frac{\alpha - E[\alpha]}{\max(\alpha) - E[\alpha]}
%\end{equation}
%\end{center}
%
%
%%Ví dụ
%\subsubsection{Ví dụ}

\section{Kết quả}
%Thực nghiệm kết quả
Sau đây, kết quả của phần thực nghiệm của thuật toán Kmeans và HAC được thể hiện dưới các bảng sau:

\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|}
\hline
\multicolumn{7}{|c|}{Kmeans}                                                                                               \\ \hline
                                                         & \multicolumn{3}{c|}{ARI}       & \multicolumn{3}{c|}{NMI}       \\ \hline
                                                         & Kmeans++ & Random   & NDArray  & Kmeans++ & Random   & NDArray  \\ \hline
Doc2Vec                                                  & 0.619478 & 0.571298 & 0.629997 & 0.805754 & 0.717114 & 0.813217 \\ \hline
TF-IDF                                                   & 0.114307 & 0.616645 & 0.117396 & 0.623300 & 0.770883 & 0.629544 \\ \hline
\begin{tabular}[c]{@{}c@{}}TF-IDF\\ Doc2Vec\end{tabular} & 0.589775 & 0.515369 &          & 0.810966 & 0.724369 &          \\ \hline
\end{tabular}%
}
\caption[Kết quả thực nghiệm Kmeans trên dữ liệu tiếng Việt]{Kết quả thực nghiệm Kmeans trên dữ liệu tiếng Việt}
\label{bang_4_6}
\end{table}

% Please add the following required packages to your document preamble:
% \usepackage{multirow}
% \usepackage{graphicx}
\begin{table}[]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|}
\hline
\multicolumn{8}{|c|}{HAC - Agglomerative Clustering}                                                                                                      \\ \hline
                                                                          &             & \multicolumn{3}{c|}{ARI}       & \multicolumn{3}{c|}{NMI}       \\ \hline
                                                                          &             & Ward     & Complete & Average  & Ward     & Complete & Average  \\ \hline
\multirow{6}{*}{Doc2Vec}                                                  & euclidean   & 0.812084 & 0.740581 & 0.417411 & 0.884622 & 0.836569 & 0.749765 \\ \cline{2-8} 
                                                                          & I1          & x        & 0.726328 & 0.423743 & x        & 0.824321 & 0.748299 \\ \cline{2-8} 
                                                                          & I2          & x        & 0.740581 & 0.417411 & x        & 0.836569 & 0.749765 \\ \cline{2-8} 
                                                                          & manhattan   & x        & 0.726328 & 0.423743 & x        & 0.824321 & 0.748299 \\ \cline{2-8} 
                                                                          & cosine      & x        & 0.740205 & 0.677730 & x        & 0.832606 & 0.805142 \\ \cline{2-8} 
                                                                          & precomputed & x        &          &          & x        &          &          \\ \hline
\multirow{6}{*}{TFIDF}                                                    & euclidean   & 0.821220 & 0.827234 & 0.722569 & 0.910135 & 0.897100 & 0.877232 \\ \cline{2-8} 
                                                                          & I1          & x        & 0.301559 & 0.031112 & x        & 0.700981 & 0.406159 \\ \cline{2-8} 
                                                                          & I2          & x        & 0.827234 & 0.722569 & x        & 0.897100 & 0.877232 \\ \cline{2-8} 
                                                                          & manhattan   & x        & 0.301559 & 0.031112 & x        & 0.700981 & 0.406159 \\ \cline{2-8} 
                                                                          & cosine      & x        & 0.787636 & 0.799860 & x        & 0.870279 & 0.878187 \\ \cline{2-8} 
                                                                          & precomputed & x        &          &          & x        &          &          \\ \hline
\multirow{6}{*}{\begin{tabular}[c]{@{}c@{}}TF-IDF\\ Doc2Vec\end{tabular}} & euclidean   & 0.837777 & 0.770857 & 0.493638 & 0.903739 & 0.863373 & 0.789117 \\ \cline{2-8} 
                                                                          & I1          & x        & 0.718870 & 0.283864 & x        & 0.844449 & 0.737149 \\ \cline{2-8} 
                                                                          & I2          & x        & 0.770857 & 0.493638 & x        & 0.863373 & 0.789117 \\ \cline{2-8} 
                                                                          & manhattan   & x        & 0.718870 & 0.283864 & x        & 0.844449 & 0.737149 \\ \cline{2-8} 
                                                                          & cosine      & x        & 0.772855 & 0.722736 & x        & 0.855602 & 0.830984 \\ \cline{2-8} 
                                                                          & precomputed & x        &          &          & x        &          &          \\ \hline
\end{tabular}%
}
\caption[Kết quả thực nghiệm HAC trên dữ liệu tiếng Việt]{Kết quả thực nghiệm HAC trên dữ liệu tiếng Việt}
\label{bang_4_7}
\end{table}

%Giải thích chi tiết(5 đoạn)
\section{Thảo luận}

%%18


