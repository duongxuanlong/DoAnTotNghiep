\chapter{Thực nghiệm và kết quả}
\label{Chapter4}
Chương này trình bày môi trường thực nghiệm của đồ án, các công cụ hỗ trợ thực nghiệm, các tập ngữ liệu được sử dụng, các công cụ dùng để đánh giá kết quả gom nhóm và kết quả của thực nghiệm.

\section{Thực nghiệm}
\subsection{Môi trường thực nghiệm}
%Môi trường thực nghiệm
Quá trình thực nghiệm đồ án được thực hiện với môi trường như sau:
\begin{enumerate}
\item[•]Ngôn ngữ lập trình Python phiên bản 2.7
\item[•]Một số gói lệnh Python cài đặt thêm:
\begin{enumerate}
\item[-] gensim phiên bản 0.11.1: gói lệnh hỗ trợ trích xuất ngữ nghĩa của các chủ đề trong các văn bản.
Gensim được thiết kế để có thể thực thi với dữ liệu thô.
Các thuật toán trong gensim như Latent Semantics Analysis(LSA), Latent Dirichlet Allocation(LDA) và Random Projections dùng để khai thác cấu trúc ngữ nghĩa của văn bản bằng các mẫu thống kê.
Sau khi chạy các thuật toán này, văn bản thô sẽ chuyển sang dạng thể hiện mới có nghĩa và có thể truy vấn độ tương đồng với các văn bản khác.
Gensim là gói lệnh dùng để giải quyết các ý tưởng về corpus, vector và mô hình.
\item[-] sklearn phiên bản 0.16.1: gói lệnh hỗ trợ máy học trong Python.
Đây là công cụ đơn giản, hiệu quả cho khai thác và phân tích dữ liệu.
Các thuật toán trong sklearn là công cụ hỗ trợ rất tốt cho các đề tài nghiên cứu.
Sklearn là mã nguồn mở, có thể được sử dụng trong thương mại.
Vì vậy, mọi người đều có thể sử dụng gói lệnh và chỉnh sửa thoải mái.
\end{enumerate}
\item[•]Ngôn ngữ lập trình C++.
\item[•]Máy tính chạy thực nghiệm
\begin{enumerate}
\item[-]CPU core i5 3.3GHz
\item[-]RAM 8GB
\item[-]Hệ điều hành windows
\end{enumerate}
\end{enumerate}

\subsection{Công cụ hỗ trợ}
\begin{table}[ht]
\begin{center}
\begin{tabularx}{\textwidth}{|c|c|X|}
\hline
STT & Tên công cụ & \makecell[c]{Mô tả} \\
\hline
1 & Google News & Công dụng: dùng để lọc ra những bài báo đã được gom nhóm. \\
\hline
2 & Java Tokenizer & Tác giả: Lê Hồng Phương - Đại học Khoa Học Tự nhiên - Đại học Quốc Gia Hà Nội. \newline Công dụng: Tách câu và tách từ cho tiếng Việt.\\
\hline
3 & sgmllib & Hỗ trợ: thư viện của Python 2.7. \newline Công dụng: dùng để trích xuất dữ liệu dưới định dạng SGML.\\
\hline
4 & C++ editor & Microsoft Visual Studio C++ 2008 \\
\hline

\end{tabularx}
\caption[Các công cụ hỗ trợ thực nghiệm]{Các công cụ hỗ trợ thực nghiệm}
\label{bang_4_1}
\end{center}
\end{table}
%\floatbarrier

\section{Dữ liệu}
%Giới thiệu dữ liệu sử dụng
Dữ liệu sử dụng trong chương trình bao gồm dữ liệu tiếng Anh và dữ liệu tiếng Việt.
Trong đó, bộ dữ liệu tiếng Việt được tổng hợp từ các trang tin tức nổi tiếng của Việt Nam như vnexpress, dân trí, tuổi trẻ, \ldots 
Các bài báo của các bộ dữ liệu được thu nhặt được thông qua trang tin tức tổng hợp của Google.
Còn bộ dữ liệu tiếng Anh là các bài báo được lấy từ trang tin tức Reuters được tổng hợp lại thành Reuters-21578.
Ngoài ra, cả hai bộ dữ liệu đều là các bài báo đã được gom nhóm sơ bộ.

%giới thiệu dữ liệu tiếng Anh
\subsection{Dữ liệu tiếng Anh}
% Giới thiệu Reuters-21578
Reuters-21578 bao gồm 21,578 bài báo thuộc nhiều lĩnh vực khác nhau.
Bộ dữ liệu này được tổng hợp bởi David D. Lewis vào năm 1987.
Đây là nguồn tài nguyên cho mục đích nghiên cứu trong lĩnh vực truy vấn thông tin, máy học, và những nghiên cứu dựa vào corpus khác.
Bộ dữ liệu này xuất bản và phân phối miễn phí cho mục đích nghiên cứu.
Nếu người nào muốn sử dụng bộ dữ liệu này thì phải đề cập đến nguồn~\footnote{http://www.research.att.com/~lewis} cũng như là thông tin tên của bộ dữ liệu cho mọi người biết.

% Mô tả Reuters-21578
Reuters-21578 là tập dữ liệu bao gồm hai mươi hai tập tin dữ liệu.
Mỗi tập tin dữ liệu là có định dạng là SGML(Standard Generalized Markup Language) và có khoảng 1000 bài báo.
Ngoài ra, bộ dữ liệu còn có sáu tập tin mô tả phân loại dùng để chỉ mục cho dữ liệu.
Tập dữ liệu còn có thêm vào những tập tin dựa vào đóng góp của những nhà nghiên cứu khác.
Tất cả những tập tin đều là không có nén, được gom lại vào thành một thư mục được nén lại thành cái tên reuters21578.tar.gz

%Giới thiệu sơ bộ về SGML
SGML~\footnote{https://www.w3.org/TR/WD-html40-970708/intro/sgmltut.html} là chuẩn cho việc định nghĩa ngôn ngữ đánh dấu cho văn bản, HTML là một trong những ứng dụng của SGML.
SGML bao gồm phần khai báo, định nghĩa loại văn bản, đặc tả và thể hiện văn bản đánh dấu.
Phần khai báo SGML là chỉ ra các kí tự và các loại dấu phân cách sẽ sử dụng.
Phần định nghĩa loại văn bản định nghĩa cú pháp của cấu trúc đánh dấu và có thể có thêm các phần định nghĩa khác như là số và tên kí tự.
Phần đặc tả mô tả ngữ nghĩa được tạo bởi đánh dấu và phần đặc tả này ràng buộc sự giới hạn của cú pháp để không thể xuất hiện trong phần định nghĩa loại văn bản.
Thể hiện văn bản chứa nội dung và đánh dấu, mỗi thể hiện chứa tham chiếu đến phần định nghĩa văn bản để thực thi nó.

%  phần phân mục của Reuters-21578
Như đã đề cập, các bài báo trong reuters-21578 đã được gom nhóm lại thành các tập phân nhóm khác nhau
\begin{table}[ht]
\begin{center}
\begin{tabularx}{\textwidth}{|Y|Y|Y|Y|}
\hline
Tập phân loại & Số lượng phân phân nhóm & Số lượng phân nhóm mà tần số lớn hơn một & Số lượng phân nhóm mà tần số lớn hơn 20  \\
\hline
EXCHANGES & 39 & 32 & 7\\
\hline
ORGS & 56 & 32 & 9\\
\hline
PEOPLE & 267 & 114 & 15 \\
\hline
PLACES & 175 & 147 & 60\\
\hline
TOPICS & 135 & 120 & 57\\
\hline
\end{tabularx}
\caption[Các tập phân loại]{Các tập phân loại}
\label{bang_4_2}
\end{center}
\end{table}

%Các tập phân loại
Phần phân loại TOPICS bao gồm các chủ đề về kinh tế.
Ví dụ phần này sẽ bao gồm các từ chính như "include", "gold", "inventories", và "money-supply".
Tập phân loại này là tập đã được sử dụng hầu hết trong các nghiên cứu về dữ liệu của Reuters.
Các tập phân loại như EXCHANGES, ORGS, PEOPLE, và PLACES được xếp nhóm có tên như mô tả, ví dụ như "nasdaq"(EXCHANGES), "gatt"(ORGS), "perez-de-cuellar"(PEOPLE), và "australia"(PLACES).

%giới thiệu dữ liệu tiếng Việt
\subsection{Dữ liệu tiếng Việt}
Bộ dữ liệu tiếng Việt do Ung Văn Giàu lấy thủ công từ Google News bao gồm 1945 bài có tổng cộng là 300 phân nhóm.
Các bài báo này đều đến từ các trang báo như: vnexpress, dân trí, tuổi trẻ, \ldots
Bộ dữ liệu có 300 phân nhóm là do bạn Giàu gán nhãn những bài vào các phân nhóm.
Mỗi phân nhóm có ít nhất là 5 bài, nhiều nhất là 10 bài.
Do đây là bộ dữ liệu làm bằng thủ công nên để đảm bảo tính chính xác thì em phân nhóm lại một lần nữa. 
Việc có hai bạn độc lập kiểm tra bộ dữ liệu nên đây là bộ dữ liệu đã được qua kiểm chứng và có thể sử dụng cho mục đích nghiên cứu.


%Các bước chuẩn bị cần thiết khi sử dụng dữ liệu

\section{Các phương pháp đánh giá}
%Các phương pháp đánh giá

%Giới thiệu các cách đánh giá
\subsection{Giới thiệu phương pháp đánh giá}
Để đánh giá kết quả gom nhóm văn bản, ta có hai loại chỉ số để sử dụng: chỉ số ngoại vi và chỉ số nội tại.
Chỉ số nội tại dùng để đo độ tốt của cấu trúc gom nhóm không cần thông tin ngoài.
Chỉ số ngoại vi dùng dùng để đo độ tương đồng giữa hai phân nhóm.
Trong đó, phân nhóm thứ nhất là cấu trúc gom nhóm gốc đã được biết.
Còn phân nhóm thứ hai là kết quả từ quá trình gom nhóm.
Trong bài toán, ta sử dụng hai chỉ số đánh giá ngoại vi là : NMI(normalized mutual information) và ARI (adjusted rand index).
	
Như đã đề cập ở phần trên, ta sẽ sử dụng hai chỉ số ngoại vi để đánh giá.
Sau đây, một vài thuật ngữ sẽ được giải thích trước khi ta bàn luận về hai chỉ số này.
Ta có tập $\textbf{C} \, = {C_1 \ldots C_j}$ là tập phân nhóm của đối tượng được xây dựng ở một cấp độ nhất định.
Tập $\textbf{P} \, = {P_1 \ldots P_j}$ là tập hợp được chia bởi phân lớp ban đầu.
$J$ và $I$ là tương đương với số phân nhóm của $(|\textbf{C}|)$ và số phân lớp của  $(|\textbf{P}|)$.
Ta biểu diễn $n$ là tổng số đối tượng trong thuật toán.

%Cách đánh giá NMI
\subsection{Cách đánh giá NMI}

%Giới thiệu
%\subsubsection{Giới thiệu}
NMI có nguồn gốc từ MI(mutual information), trong đó MI sử dụng hướng tiếp cận là so sánh phân nhóm có nguồn gốc trong lý thuyết thông tin và dựa vào ý tưởng của entropy.
Gọi $S$ là entropy cho thông tin của văn bản $T$, ta có công thức sau:
\begin{center}
\begin{equation}
S(T) \, = -\sum_{i \in \sum} p_i \log_2 (p_i)
\end{equation}
\end{center}

Với $p_i$ là xác xuất của việc tìm kiếm $i$ trong $T$, hay chính xác hơn là ta có biến ngẫu nhiên rời rạc $Y$ lấy giá trị từ $\mid \sum \mid$ và $P(Y \, = \, i) \, = \, p_i$.
Giá trị entropy được được tính bằng số bit và $S(T)$, trong đó thì $\mid T \mid$ là số lượng bit cần để biểu diễn cho $T$.

Khi áp dụng gom nhóm, ý nghĩa của entropy được mô tả như sau: giả sử tất cả những thành phần của $X$ có xác xuất được chọn là giống nhau và chọn một thành phần ngẫu nhiên của $X$, xác xuất của thành phần này nằm trong phân nhóm $C_i \in C$ là $P(i) = \frac{\mid C_i \mid}{n}$.
Khi đó, entropy kết hợp với phân nhóm $C$ cho ra công thức:
\begin{center}
\begin{equation}
H (C) = - \sum^{k}_{i = 1} P(i) \log_2 P(i)
\end{equation}
\end{center}

NMI có nguốn gốc từ MI(mutual information), được sử dụng nhiều trong lý thuyết xác suất và lý thuyết thông tin.
NMI là phương pháp đo độ phụ thuộc lẫn nhau giữa hai biến.
Trong đây, NMI được nâng cấp để đo phụ thuộc lẫn nhau giữa hai nhóm.
Từ đó, NMI cung cấp thông tin cân bằng liên quan đến số lượng phân nhóm.
Ngoài ra, NMI còn cho ra kết quả chia sẻ thông tin với lớp thực sự được gán và thông tin hỗn hợp trung bình giữa những cặp của phân nhóm và phân lớp.
		
%Công thức
%\subsubsection{Công thức}
\begin{center}
\begin{equation}
\textbf{NMI} \, = \frac{\sum^I_{i=1} \sum^J_{j=1} x_{ij} \log \frac{n x_{ij}}{x_i x_j}}{\sqrt{\sum^I_{i=1} x_i \log \frac{x_i}{n} \sum^J_{j=1} x_j \log \frac{x_j}{n}}}
\end{equation}
\end{center}
		
Với $x_{ij}$ là số lượng phần tử của các đối tượng mà xuất hiện trong cả tập $C_j$ và $P_i$.
$x_j$ là số lượng phần tử chỉ xuất hiện trong tập $C_j$. $x_i$ là số lượng phần tử chỉ xuất hiện trong tập $P_i$.
Giá trị của chỉ số này nằm trong khoảng từ 0 đến 1.

%Ví dụ
%\subsubsection{Ví dụ}
		
%Cách đánh giá ARI
\subsection{Cách đánh giá ARI}
%Giới thiệu
\subsubsection{Giới thiệu}
ARI có nguồn gốc từ RI (rand index), được sử dụng thống kê và gom nhóm dữ liệu.
RI dùng để đo độ tương đồng giữa các nhóm dữ liệu.
Vấn đề của RI là giá trị mong muốn của hai phân nhóm ngẫu nhiên nằm trong khoảng từ $0$ và $1$.
Vì vậy, ARI ra đời là phiên bản chỉnh sửa có thể định nghĩa cho việc điều chỉnh cho cơ hội gom nhóm các thành phần.
Giá trị của ARI có thể nằm trong phạm vi từ -1 đến 1.

%Công thức
\subsubsection{Công thức}
\begin{center}
\begin{equation}
E[\alpha] \, = \frac{\pi(C) \cdot \pi(P)}{n(n - 1) / 2}
\end{equation}
\end{center}
		
Với $\pi(C)$ và $\pi(P)$ biểu thị tương ứng với số lượng các cặp đối tượng của cùng phân nhóm trong $\textbf{C}$ và cùng phân lớp trong $\textbf{P}$. Giá trị lớn nhất cho $\alpha$ có thể đạt được là:
\begin{center}
\begin{equation}
\max(\alpha) = \frac{1}{2} (\pi(C) + \pi(P))
\end{equation}
\end{center}
		
Độ tương đồng giữa $\textbf{C}$ và $\textbf{P}$ có thể được ước lượng bởi adjusted rand index như sau:
\begin{center}
\begin{equation}
AR(\textbf{C}, \textbf{P}) = \frac{\alpha - E[\alpha]}{\max(\alpha) - E[\alpha]}
\end{equation}
\end{center}

%Ví dụ
\subsubsection{Ví dụ}

\section{Kết quả}
%Thực nghiệm kết quả

%Giải thích chi tiết(5 đoạn)
\section{Thảo luận}

%%18


